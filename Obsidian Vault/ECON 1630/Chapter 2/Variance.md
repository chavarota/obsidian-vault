Variances measure the squared spread of a [[Random Variables|random variable]]:
$$Var(X)=E[(X-E[X])^2]=E[X^2]-E[X]^2$$
The standard deviation is the square root of the variance.

**Variance of a linear transformation:** $Var(a+bX)=b^2Var(X)$

This implies that $Std(a + bX) = b \times Std(X)$. (Intuitively, if I measure income in cents, the standard deviation should be 100 times if I measure it in dollars.)